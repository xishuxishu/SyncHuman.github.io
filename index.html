<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>SyncHuman: Synchronizing 2D and 3D Generative Models for Single-view Human Reconstruction</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              SyncHuman: Synchronizing 2D and 3D Generative Models for Single-view Human Reconstruction
            </h1>
            <div class="is-size-5 publication-authors" style="text-align: center; margin: 10px 0;">
                  NeurIPS 2025
            </div>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href target="_blank">Wenyue Chen<sup>1</sup></a>,</span>
                <span class="author-block">
                      <a href="https://scholar.google.com/citations?user=8eTLCkwAAAAJ&hl" target="_blank">Peng Li<sup>2&dagger;</sup></a>,</span>
                      <span class="author-block">
                        <a href="https://wangguandongzheng.github.io/" target="_blank">Wangguandong Zheng<sup>3</sup></a>,</span>
                        <span class="author-block">
                            <a href="https://afterjourney00.github.io/" target="_blank">Chengfeng Zhao<sup>2</sup></a>,</span>
                            <span class="author-block">
                              <a href target="_blank">Mengfei Li<sup>2</sup></a>,</span>
                              <span class="author-block">
                                <a href target="_blank">Yaolong Zhu<sup>1</sup></a>,</span>
                                <span class="author-block">
                                  <a href="https://frank-zy-dou.github.io/" target="_blank">Zhiyang Dou<sup>4</sup></a>,</span>
                                   <span class="author-block">
                                    <a href="https://scholar.google.com/citations?user=CEEvb64AAAAJ&hl" target="_blank">Ronggang Wang<sup>1</sup></a>,</span>
                                    <span class="author-block">
                                      <a href="https://liuyuan-pal.github.io/" target="_blank">Yuan Liu<sup>2&dagger;</sup></a></span>
                                      </div>

                                      <div class="is-size-5 publication-authors">
                                        <span class="author-block">
                                          <sup>1</sup>Peking University, 
                                          <sup>2</sup>The Hong Kong University of Science and Technology,
                                          <sup>3</sup>Southeast University,<br>
                                          <sup>4</sup>The University of Hong Kong
                       
                                        </span>
                                      </div>

                                      <div class="column has-text-centered">
                                        <div class="publication-links">
                                           <!-- Arxiv PDF link -->
                                        <span class="link-block">
                                          <a href="https://arxiv.org/pdf/2501.03847.pdf" target="_blank"
                                          class="external-link button is-normal is-rounded is-dark">
                                          <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                          </span>
                                          <span>Paper</span>
                                        </a>
                                      </span>

                                    <!-- Github link -->
                                    <span class="link-block">
                                      <a href="https://github.com/IGL-HKUST/DiffusionAsShader" target="_blank"
                                      class="external-link button is-normal is-rounded is-dark">
                                      <span class="icon">
                                        <i class="fab fa-github"></i>
                                      </span>
                                      <span>Code</span>
                                    </a>
                                  </span>


                              </div>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- Teaser image -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div style="margin: 5px 0; text-align: center;">
       <img src="static/assets/teaser.png" alt="SyncHuman Demo" 
       style="max-width: 90%; height: auto; border-radius: 8px; display: inline-block;">
        </div>
      <h2 class="subtitle has-text-centered">
        We introduce <strong>SyncHuman</strong>, a full-body human reconstruction model using synchronized <br> 2D and 3D generative model. Given a single image of a clothed person, our method <br>  generates detailed geometry and lifelike 3D human appearances across diverse poses.
      </h2>
         </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Photorealistic 3D full-body human reconstruction from a single image is a critical yet challenging task for applications in films and video games due to inherent ambiguities and severe self-occlusions. While recent approaches leverage SMPL estimation and SMPL-conditioned image generative models to hallucinate novel views, they suffer from inaccurate 3D priors estimated from SMPL meshes and have difficulty in handling difficult human poses and reconstructing fine details.In this paper, we propose SyncHuman, a novel framework that combines 2D multiview generative model and 3D native generative model for the first time, enabling high-quality clothed human mesh reconstruction from single-view images even under challenging human poses.Multiview generative model excels at capturing fine 2D details but struggles with structural consistency, whereas 3D native generative model generates coarse yet structurally consistent 3D shapes. By integrating the complementary strengths of these two approaches, we develop a more effective generation framework. Specifically, we first jointly fine-tune the multiview generative model and the 3D native generative model with proposed pixel-aligned 2D-3D synchronization attention to produce geometrically aligned 3D shapes and 2D multiview images. To further improve details, we introduce a feature injection mechanism that lifts fine details from 2D multiview images onto the aligned 3D shapes, enabling accurate and high-fidelity reconstruction.Extensive experiments demonstrate that SyncHuman achieves robust and photorealistic 3D human reconstruction, even for images with challenging poses. Our method outperforms baseline methods in geometric accuracy and visual fidelity, demonstrating a promising direction for future 3D generation models.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<section class="hero teaser" style="background-color: #fafafa;">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div style="margin: 5px 0; text-align: center;">
       <h2 class="title is-3">Method</h2>
       <img src="static/assets/pipeline.png" alt="SyncHuman Demo" style="max-width: 100%; height: auto; border-radius: 8px; display: inline-block;">
        </div>
      <div class="content has-text-justified">
          <p>
           Given a single human image, SyncHuman first generates multiview color and normal maps, along with an aligned sparse voxel grid, which is further transformed into a set of structured latents. Then, we propose to inject the high-quality images into the 3D latents via a Multiview Guided Decoder and output the detailed high-fidelity textured human mesh.
          </p>
         <img src="static/assets/att.png" alt="SyncHuman Demo" style="max-width: 100%; height: auto; border-radius: 8px; display: inline-block;">
               <p>
            <strong>2D-3D synchronization attention.</strong> <strong>2D to 3D attention: </strong>each 3D voxel feature is orthogonally projected onto front, back, left, and right view planes to retrieve corresponding 2D features, and refines the voxel feature with cross-attention. <strong>3D to 2D attention: </strong>each 2D multiview feature is projected into 3D space to attend to a column of voxel features, enhancing the 2D features.This mutual refinement ensures that 2D generative model and 3D generative model align with each other in a shared 3D space.Given a single human image, SyncHuman first generates multiview color and normal maps, along with an aligned sparse voxel grid, which is further transformed into a set of structured latents. Then, we propose to inject the high-quality images into the 3D latents via a Multiview Guided Decoder and output the detailed high-fidelity textured human mesh.
          </p>
      </h2>
    </div>
  </div>
</section>

<!-- <section class="hero teaser" style="background-color:  #f5f5f5;">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div style="margin: 5px 0; text-align: center;">
       <h2 class="title is-3">Comparison</h2>
       <div style="margin-top: 10px;"></div>
       <video poster="" id="teaser" autoplay muted loop controlsList="nodownload" playsinline style="max-width: 100%; height: auto; border-radius: 8px; display: inline-block;">
         <source src="static/assets/compare.mp4" type="video/mp4">
       </video>
      </div>
    </div>
  </div>
</section> -->

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
    <div style="margin: 5px 0; text-align: center;">
       <h2 class="title is-3">Comparision</h2>
      <div style="margin-top: 30px;"></div>
      <video poster="" id="teaser" autoplay muted loop controlsList="nodownload" playsinline>
        <!-- Your video file here -->
        <source src="static/assets/compare.mp4"
        type="video/mp4">
      </video>
    </div>
  </div>
</section>

<section class="hero teaser" style="background-color: #f5f5f5;">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div style="margin: 5px 0; text-align: center;">
       <h2 class="title is-3">More Results</h2>
       <div style="margin-top: 10px;"></div>
       <video poster="" id="teaser" autoplay muted loop controlsList="nodownload" playsinline>
         <source src="static/assets/more1.mp4" type="video/mp4">
       </video>

     <video poster="" id="teaser" autoplay muted loop controlsList="nodownload" playsinline>
         <source src="static/assets/more2.mp4" type="video/mp4">
       </video>

     <video poster="" id="teaser" autoplay muted loop controlsList="nodownload" playsinline>
         <source src="static/assets/more3.mp4" type="video/mp4">
       </video>

      </div>
    </div>
  </div>
</section>



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{chen2025SyncHuman,
        title={SyncHuman: Synchronizing 2D and 3D Generative Models for Single-view Human Reconstruction}, 
         author={Wenyue Chen, Peng Li, Wangguandong Zheng, Chengfeng Zhao, Mengfei Li, Yaolong Zhu, Zhiyang Dou, Ronggang Wang, Yuan Liu},
         year={2025},
         journal={arXiv preprint arXiv:2501.03847}
        }
        </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
          We thank the <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> team for providing this amazing website template.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->

<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
